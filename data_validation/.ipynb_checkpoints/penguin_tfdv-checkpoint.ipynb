{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4638e4",
   "metadata": {},
   "source": [
    "# Data validation using TFX Pipeline and TensorFlow Data Validation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a662b992",
   "metadata": {},
   "source": [
    "The first task in any data science or ML project is to understand and clean the data, which includes:\n",
    "\n",
    "* Understanding the data types, distributions, and other information (e.g., mean value, or number of uniques) about each feature\n",
    "\n",
    "* Generating a preliminary schema that describes the data\n",
    "\n",
    "* Identifying anomalies and missing values in the data with respect to given schema\n",
    "\n",
    "In this tutorial, we will create two TFX pipelines.\n",
    "\n",
    "First, we will create a pipeline to analyze the dataset and generate a preliminary schema of the given dataset. This pipeline will include two new components, StatisticsGen and SchemaGen.\n",
    "\n",
    "Once we have a proper schema of the data, we will create a pipeline to train an ML classification model based on the pipeline from the previous tutorial. In this pipeline, we will use the schema from the first pipeline and a new component, ExampleValidator, to validate the input data.\n",
    "\n",
    "The three new components, StatisticsGen, SchemaGen and ExampleValidator, are TFX components for data analysis and validation, and they are implemented using the TensorFlow Data Validation library.\n",
    "\n",
    "Please see Understanding TFX Pipelines to learn more about various concepts in TFX.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c527ff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# We will create two pipelines. One for schema generation and one for training.\n",
    "SCHEMA_PIPELINE_NAME = \"penguin-tfdv-schema\"\n",
    "PIPELINE_NAME = \"penguin-tfdv\"\n",
    "\n",
    "# Output directory to store artifacts generated from the pipeline.\n",
    "SCHEMA_PIPELINE_ROOT = os.path.join('pipelines', SCHEMA_PIPELINE_NAME)\n",
    "PIPELINE_ROOT = os.path.join('pipelines', PIPELINE_NAME)\n",
    "# Path to a SQLite DB file to use as an MLMD storage.\n",
    "SCHEMA_METADATA_PATH = os.path.join('metadata', SCHEMA_PIPELINE_NAME,\n",
    "                                    'metadata.db')\n",
    "METADATA_PATH = os.path.join('metadata', PIPELINE_NAME, 'metadata.db')\n",
    "\n",
    "# Output directory where created models from the pipeline will be exported.\n",
    "SERVING_MODEL_DIR = os.path.join('serving_model', PIPELINE_NAME)\n",
    "\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)  # Set default logging level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc5262a",
   "metadata": {},
   "source": [
    "## Prepare example data\n",
    "\n",
    "\n",
    "We will download the example dataset for use in our TFX pipeline. The dataset we are using is Palmer Penguins dataset which is also used in other TFX examples.\n",
    "\n",
    "There are four numeric features in this dataset:\n",
    "\n",
    "culmen_length_mm\n",
    "\n",
    "culmen_depth_mm\n",
    "\n",
    "flipper_length_mm\n",
    "\n",
    "body_mass_g\n",
    "\n",
    "All features were already normalized to have range [0,1]. We will build a classification model which predicts the species of penguins.\n",
    "\n",
    "Because the TFX ExampleGen component reads inputs from a directory, we need to create a directory and copy the dataset to it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cde1ffe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tmp/tfx-datau5zuvxvf/data.csv', <http.client.HTTPMessage at 0x7f040044b5d0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "DATA_ROOT = tempfile.mkdtemp(prefix='tfx-data')  # Create a temporary directory.\n",
    "_data_url = 'https://raw.githubusercontent.com/tensorflow/tfx/master/tfx/examples/penguin/data/labelled/penguins_processed.csv'\n",
    "_data_filepath = os.path.join(DATA_ROOT, \"data.csv\")\n",
    "urllib.request.urlretrieve(_data_url, _data_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057b26e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\r\n",
      "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\r\n",
      "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\r\n",
      "0,0.29818181818181805,0.5833333333333334,0.3898305084745763,0.1527777777777778\r\n",
      "0,0.16727272727272732,0.7380952380952381,0.3559322033898305,0.20833333333333334\r\n",
      "0,0.26181818181818167,0.892857142857143,0.3050847457627119,0.2638888888888889\r\n",
      "0,0.24727272727272717,0.5595238095238096,0.15254237288135594,0.2569444444444444\r\n",
      "0,0.25818181818181823,0.773809523809524,0.3898305084745763,0.5486111111111112\r\n",
      "0,0.32727272727272727,0.5357142857142859,0.1694915254237288,0.1388888888888889\r\n",
      "0,0.23636363636363636,0.9642857142857142,0.3220338983050847,0.3055555555555556\r\n"
     ]
    }
   ],
   "source": [
    "!head {_data_filepath}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc45810",
   "metadata": {},
   "source": [
    "You should be able to see five feature columns. species is one of 0, 1 or 2, and all other features should have values between 0 and 1. We will create a TFX pipeline to analyze this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b0596",
   "metadata": {},
   "source": [
    "## Generate a preliminary schema\n",
    "TFX pipelines are defined using Python APIs. We will create a pipeline to generate a schema from the input examples automatically. This schema can be reviewed by a human and adjusted as needed. Once the schema is finalized it can be used for training and example validation in later tasks.\n",
    "\n",
    "In addition to CsvExampleGen which is used in Simple TFX Pipeline Tutorial, we will use StatisticsGen and SchemaGen:\n",
    "\n",
    "* StatisticsGen calculates statistics for the dataset.\n",
    "* SchemaGen examines the statistics and creates an initial data schema.\n",
    "See the guides for each component or TFX components tutorial to learn more on these components.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d1476",
   "metadata": {},
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "We define a function to create a TFX pipeline. A Pipeline object represents a TFX pipeline which can be run using one of pipeline orchestration systems that TFX supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2412234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_schema_pipeline(pipeline_name: str,\n",
    "                            pipeline_root: str,\n",
    "                            data_root: str,\n",
    "                            metadata_path: str) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a pipeline for schema generation.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # NEW: Computes statistics over data for visualization and schema generation.\n",
    "  statistics_gen = tfx.components.StatisticsGen(\n",
    "      examples=example_gen.outputs['examples'])\n",
    "\n",
    "  # NEW: Generates schema based on the generated statistics.\n",
    "  schema_gen = tfx.components.SchemaGen(\n",
    "      statistics=statistics_gen.outputs['statistics'], infer_feature_shape=True)\n",
    "\n",
    "  components = [\n",
    "      example_gen,\n",
    "      statistics_gen,\n",
    "      schema_gen,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      metadata_connection_config=tfx.orchestration.metadata\n",
    "      .sqlite_metadata_connection_config(metadata_path),\n",
    "      components=components)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
